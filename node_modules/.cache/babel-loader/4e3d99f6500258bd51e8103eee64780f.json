{"ast":null,"code":"/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n\tAuthor Tobias Koppers @sokra\n*/\n\"use strict\";\n\nvar _createForOfIteratorHelper = require(\"C:\\\\Users\\\\ANIKE\\\\Desktop\\\\Udemy\\\\Web Developing\\\\keeper-app-part-1-starting\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/createForOfIteratorHelper\");\n\nvar _classCallCheck = require(\"C:\\\\Users\\\\ANIKE\\\\Desktop\\\\Udemy\\\\Web Developing\\\\keeper-app-part-1-starting\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"C:\\\\Users\\\\ANIKE\\\\Desktop\\\\Udemy\\\\Web Developing\\\\keeper-app-part-1-starting\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/createClass\");\n\nvar MergeDuplicateChunksPlugin = /*#__PURE__*/function () {\n  function MergeDuplicateChunksPlugin() {\n    _classCallCheck(this, MergeDuplicateChunksPlugin);\n  }\n\n  _createClass(MergeDuplicateChunksPlugin, [{\n    key: \"apply\",\n    value: function apply(compiler) {\n      compiler.hooks.compilation.tap(\"MergeDuplicateChunksPlugin\", function (compilation) {\n        compilation.hooks.optimizeChunksBasic.tap(\"MergeDuplicateChunksPlugin\", function (chunks) {\n          // remember already tested chunks for performance\n          var notDuplicates = new Set(); // for each chunk\n\n          var _iterator = _createForOfIteratorHelper(chunks),\n              _step;\n\n          try {\n            for (_iterator.s(); !(_step = _iterator.n()).done;) {\n              var chunk = _step.value;\n              // track a Set of all chunk that could be duplicates\n              var possibleDuplicates = void 0;\n\n              var _iterator2 = _createForOfIteratorHelper(chunk.modulesIterable),\n                  _step2;\n\n              try {\n                for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n                  var _module = _step2.value;\n\n                  if (possibleDuplicates === undefined) {\n                    // when possibleDuplicates is not yet set,\n                    // create a new Set from chunks of the current module\n                    // including only chunks with the same number of modules\n                    var _iterator4 = _createForOfIteratorHelper(_module.chunksIterable),\n                        _step4;\n\n                    try {\n                      for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n                        var dup = _step4.value;\n\n                        if (dup !== chunk && chunk.getNumberOfModules() === dup.getNumberOfModules() && !notDuplicates.has(dup)) {\n                          // delay allocating the new Set until here, reduce memory pressure\n                          if (possibleDuplicates === undefined) {\n                            possibleDuplicates = new Set();\n                          }\n\n                          possibleDuplicates.add(dup);\n                        }\n                      } // when no chunk is possible we can break here\n\n                    } catch (err) {\n                      _iterator4.e(err);\n                    } finally {\n                      _iterator4.f();\n                    }\n\n                    if (possibleDuplicates === undefined) break;\n                  } else {\n                    // validate existing possible duplicates\n                    var _iterator5 = _createForOfIteratorHelper(possibleDuplicates),\n                        _step5;\n\n                    try {\n                      for (_iterator5.s(); !(_step5 = _iterator5.n()).done;) {\n                        var _dup = _step5.value;\n\n                        // remove possible duplicate when module is not contained\n                        if (!_dup.containsModule(_module)) {\n                          possibleDuplicates.delete(_dup);\n                        }\n                      } // when all chunks has been removed we can break here\n\n                    } catch (err) {\n                      _iterator5.e(err);\n                    } finally {\n                      _iterator5.f();\n                    }\n\n                    if (possibleDuplicates.size === 0) break;\n                  }\n                } // when we found duplicates\n\n              } catch (err) {\n                _iterator2.e(err);\n              } finally {\n                _iterator2.f();\n              }\n\n              if (possibleDuplicates !== undefined && possibleDuplicates.size > 0) {\n                var _iterator3 = _createForOfIteratorHelper(possibleDuplicates),\n                    _step3;\n\n                try {\n                  for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n                    var otherChunk = _step3.value;\n                    if (otherChunk.hasRuntime() !== chunk.hasRuntime()) continue; // merge them\n\n                    if (chunk.integrate(otherChunk, \"duplicate\")) {\n                      chunks.splice(chunks.indexOf(otherChunk), 1);\n                    }\n                  }\n                } catch (err) {\n                  _iterator3.e(err);\n                } finally {\n                  _iterator3.f();\n                }\n              } // don't check already processed chunks twice\n\n\n              notDuplicates.add(chunk);\n            }\n          } catch (err) {\n            _iterator.e(err);\n          } finally {\n            _iterator.f();\n          }\n        });\n      });\n    }\n  }]);\n\n  return MergeDuplicateChunksPlugin;\n}();\n\nmodule.exports = MergeDuplicateChunksPlugin;","map":null,"metadata":{},"sourceType":"script"}